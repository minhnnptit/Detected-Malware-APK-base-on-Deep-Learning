{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADRp2n6JEWIH"
      },
      "source": [
        "### construct and prune FCG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJnTQYonESJ-"
      },
      "outputs": [],
      "source": [
        "!pip install androguard\n",
        "!pip install loguru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2pxtNaNFJl2"
      },
      "outputs": [],
      "source": [
        "from loguru import logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQNDaT8HFb1g"
      },
      "outputs": [],
      "source": [
        "logger.disable(\"androguard\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLjpTCZtFgPe"
      },
      "outputs": [],
      "source": [
        "from androguard.core.bytecode import FormatClassToJava\n",
        "from androguard.misc import AnalyzeAPK\n",
        "from androguard.core.analysis.analysis import MethodAnalysis, ExternalMethod\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0BiiR1TFvLd"
      },
      "outputs": [],
      "source": [
        "def find_ancestor(node: MethodAnalysis, family: list):\n",
        "    for _, parent, _ in node.get_xref_from():\n",
        "        if parent not in family:\n",
        "            family.append(parent)\n",
        "            find_ancestor(parent, family)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztj4w285Gf5w"
      },
      "outputs": [],
      "source": [
        "def cg(apk):\n",
        "    a, d, dx = AnalyzeAPK(apk)\n",
        "    entry_points = map(\n",
        "        FormatClassToJava,\n",
        "        a.get_activities() + a.get_providers() + a.get_services() + a.get_receivers(),\n",
        "    )\n",
        "    entry_points = list(entry_points)\n",
        "\n",
        "    callgraph = dx.get_call_graph(no_isolated=True, entry_points=entry_points)\n",
        "\n",
        "    important_nodes = []\n",
        "    for meth, _ in dx.get_permissions(a.get_effective_target_sdk_version()):\n",
        "        if meth not in important_nodes:\n",
        "            important_nodes.append(meth)\n",
        "            find_ancestor(meth, important_nodes)\n",
        "\n",
        "    for node in important_nodes[:]:\n",
        "        for _, child, _ in node.get_xref_to():\n",
        "            if child not in important_nodes:\n",
        "                important_nodes.append(child)\n",
        "\n",
        "    important_nodes = [node.get_method() for node in important_nodes]\n",
        "    callgraph.remove_nodes_from(set(callgraph.nodes) - set(important_nodes))\n",
        "\n",
        "    return callgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Z1Uf6hMFEW"
      },
      "source": [
        "### enhance FCG: assign code_vector to nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhKcfktOL-M4"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/bdqnghi/infercode.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8y1Fc72Mot-"
      },
      "outputs": [],
      "source": [
        "%cd infercode\n",
        "!pip install .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIkxFqSpM5JR"
      },
      "outputs": [],
      "source": [
        "!unzip /root/.tree-sitter/Linux.zip -d /root/.tree-sitter/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYHtChthNG2_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Change from -1 to 0 to enable GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "\n",
        "logging.getLogger(\"tensorflow\").disabled = True\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "try:\n",
        "    # Disable all GPUS\n",
        "    tf.config.set_visible_devices([], \"GPU\")\n",
        "    visible_devices = tf.config.get_visible_devices()\n",
        "    for device in visible_devices:\n",
        "        assert device.device_type != \"GPU\"\n",
        "except:\n",
        "    # Invalid device or cannot modify virtual devices once initialized.\n",
        "    pass\n",
        "\n",
        "from infercode.client.infercode_client import InferCodeClient\n",
        "\n",
        "infercode = InferCodeClient(language=\"java\")\n",
        "infercode.init_from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mVVQK8_Ofm5"
      },
      "outputs": [],
      "source": [
        "def enhance_fcg(fcg: nx.DiGraph):\n",
        "    mappings = {}\n",
        "    for node in fcg.nodes:\n",
        "        if isinstance(node, ExternalMethod):\n",
        "            code_vector = infercode.encode([node.get_name()])\n",
        "        else:\n",
        "            code_vector = infercode.encode([node.get_source()])\n",
        "        mappings[node] = code_vector.reshape(-1)\n",
        "    nx.set_node_attributes(G=fcg, values=mappings, name=\"code_vector\")\n",
        "\n",
        "    for node in fcg.nodes:\n",
        "        fcg.nodes[node][\"external\"] = int(fcg.nodes[node][\"external\"])\n",
        "        del fcg.nodes[node][\"entrypoint\"]\n",
        "        del fcg.nodes[node][\"methodname\"]\n",
        "        del fcg.nodes[node][\"descriptor\"]\n",
        "        del fcg.nodes[node][\"accessflags\"]\n",
        "        del fcg.nodes[node][\"classname\"]\n",
        "\n",
        "    return fcg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ_Ic03oRFCe"
      },
      "source": [
        "### Networkx to PyTorch Geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SAxoXjMQ8jS"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRmabfi9RVRH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTWXQly2RrBX"
      },
      "outputs": [],
      "source": [
        "def nx_to_pyg(fcg: nx.DiGraph, label: int):\n",
        "    fcg = nx.convert_node_labels_to_integers(fcg)\n",
        "\n",
        "    dg = torch_geometric.utils.from_networkx(\n",
        "        G=fcg, group_node_attrs=[\"code_vector\", \"external\"]\n",
        "    )\n",
        "\n",
        "    # y = 0 if label == \"Benign\" else 1\n",
        "    dg.y = torch.tensor([label])\n",
        "\n",
        "    return dg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ7F5Tik_yWQ"
      },
      "source": [
        "### create dataset of graph for GIN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGfgTTO2BGAo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1tEdZH2BHOQ"
      },
      "outputs": [],
      "source": [
        "ben_dir = \"/content/benign\"\n",
        "mal_dir = \"/content/malware5\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ben_dir)"
      ],
      "metadata": {
        "id": "ukgasueeLrzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUFCvaxS_4n3"
      },
      "outputs": [],
      "source": [
        "def create_dataset(data_dir: str, label: str):\n",
        "    y = 0 if label == \"Benign\" else 1\n",
        "    dataset = []\n",
        "    # cnt = 0\n",
        "    for apk in Path(data_dir).iterdir():\n",
        "        # if cnt == 20:\n",
        "        #   break\n",
        "        try:\n",
        "            fcg = cg(str(apk))\n",
        "            efcg = enhance_fcg(fcg)\n",
        "            dg = nx_to_pyg(efcg, y)\n",
        "            dataset.append(dg)\n",
        "            # cnt += 1\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQzzGfFoEI_n"
      },
      "outputs": [],
      "source": [
        "ben_dataset = create_dataset(ben_dir, \"Benign\")\n",
        "mal_dataset = create_dataset(mal_dir, \"Malware\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkeidVttl_D7"
      },
      "outputs": [],
      "source": [
        "len(ben_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NO7EMY5wEDHr"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt-MKa6sEV5f"
      },
      "outputs": [],
      "source": [
        "dataset = [sample for sub in zip(ben_dataset, mal_dataset) for sample in sub]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHEzkTBt18Ve"
      },
      "outputs": [],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqS9GHDvKioB"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8IDMT5sEk-l"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[:int(len(dataset)*0.8)]\n",
        "val_dataset   = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]\n",
        "test_dataset  = dataset[int(len(dataset)*0.9):]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(test_dataset), len(val_dataset)"
      ],
      "metadata": {
        "id": "ZQhyMbfQUYtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4pq38pNElgd"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGh4ntifEnX2"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQb-jbXHI96j"
      },
      "source": [
        "### GIN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTF4WPCaI9TS"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GINConv\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "O1KZ7sfAKep8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsBprS1aOyUy"
      },
      "outputs": [],
      "source": [
        "num_node_features = dataset[0].x.shape[1]\n",
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bXf4XQ92gGe"
      },
      "outputs": [],
      "source": [
        "num_node_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtpfx7VM-DMC"
      },
      "outputs": [],
      "source": [
        "class GIN(torch.nn.Module):\n",
        "    \"\"\"GIN\"\"\"\n",
        "    def __init__(self, dim_h):\n",
        "        super(GIN, self).__init__()\n",
        "        self.conv1 = GINConv(\n",
        "            Sequential(Linear(num_node_features, dim_h),\n",
        "                       BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.conv2 = GINConv(\n",
        "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.conv3 = GINConv(\n",
        "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.conv4 = GINConv(\n",
        "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.conv5 = GINConv(\n",
        "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.lin1 = Linear(dim_h*5, dim_h*3)\n",
        "        self.lin2 = Linear(dim_h*3, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # Node embeddings\n",
        "        h1 = self.conv1(x, edge_index)\n",
        "        h2 = self.conv2(h1, edge_index)\n",
        "        h3 = self.conv3(h2, edge_index)\n",
        "        h4 = self.conv3(h3, edge_index)\n",
        "        h5 = self.conv3(h4, edge_index)\n",
        "\n",
        "        # Graph-level readout\n",
        "        h1 = global_add_pool(h1, batch)\n",
        "        h2 = global_add_pool(h2, batch)\n",
        "        h3 = global_add_pool(h3, batch)\n",
        "        h4 = global_add_pool(h4, batch)\n",
        "        h5 = global_add_pool(h5, batch)\n",
        "\n",
        "        # Concatenate graph embeddings\n",
        "        hG = torch.cat((h1, h2, h3, h4, h5), dim=1)\n",
        "\n",
        "        # Classifier\n",
        "        h = self.lin1(hG)\n",
        "        h = h.relu()\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h = self.lin2(h)\n",
        "\n",
        "        return hG, F.log_softmax(h, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm3QCDZoX6KK"
      },
      "outputs": [],
      "source": [
        "gin = GIN(dim_h=32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gin.to(device)"
      ],
      "metadata": {
        "id": "rJdYVm6nKkZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I67z5GKUYCvo"
      },
      "outputs": [],
      "source": [
        "def train(model, loader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                      lr=0.01,\n",
        "                                      weight_decay=0.01)\n",
        "    epochs = 50\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs+1):\n",
        "        total_loss = 0\n",
        "        acc = 0\n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "\n",
        "        # Train on batches\n",
        "        for data in loader:\n",
        "          optimizer.zero_grad()\n",
        "          data = data.to(device)\n",
        "          _, out = model(data.x, data.edge_index, data.batch)\n",
        "          loss = criterion(out, data.y)\n",
        "          total_loss += loss / len(loader)\n",
        "          acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Validation\n",
        "          val_loss, val_acc = test(model, val_loader)\n",
        "\n",
        "        # Print metrics every 10 epochs\n",
        "        if(epoch % 10 == 0):\n",
        "            print(f'Epoch {epoch:>3} | Train Loss: {total_loss:.2f} '\n",
        "                  f'| Train Acc: {acc*100:>5.2f}% '\n",
        "                  f'| Val Loss: {val_loss:.2f} '\n",
        "                  f'| Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "    test_loss, test_acc = test(model, test_loader)\n",
        "    print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')\n",
        "\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        _, out = model(data.x, data.edge_index, data.batch)\n",
        "        loss += criterion(out, data.y) / len(loader)\n",
        "        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "def accuracy(pred_y, y):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return ((pred_y == y).sum() / len(y)).item()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3Ej3ZLiadrn"
      },
      "outputs": [],
      "source": [
        "gin = train(gin, train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKVdnHK5JDEM"
      },
      "source": [
        "### Graph embedding vector to CSV for RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8utlubPLJVHg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VewpyhLzJY9H"
      },
      "outputs": [],
      "source": [
        "def create_df(dataset):\n",
        "    tmp = []\n",
        "    for data in dataset:\n",
        "        gvector, out = gin(data.x, data.edge_index, data.batch)\n",
        "        if out.argmax(dim=1) == data.y:\n",
        "            tmp.append(np.append(gvector.detach().numpy().reshape(-1), data.y.numpy()))\n",
        "\n",
        "    return pd.DataFrame(np.array(tmp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oygIcuPhMrRw"
      },
      "outputs": [],
      "source": [
        "df = create_df(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFU5ZARNrX4r"
      },
      "outputs": [],
      "source": [
        "df = df.loc[:, (df.nunique() > 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVrGTzRk64KS"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"datatest02.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuVfNcAh7JXI"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NJ6zEQVrvXb"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofivWswdrwmy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mmB4Z2Qr3Qi"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"datatest02.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKVdGtOcsBm8"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRyZ31UYsFGq"
      },
      "outputs": [],
      "source": [
        "X = df.drop(\"96\", axis=1)\n",
        "y = df[\"96\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFhSFs6IsGH6"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkxvV021sKD7"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCxTCpaXsLGb"
      },
      "outputs": [],
      "source": [
        "y_pred = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bT_z9jJsN47"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}